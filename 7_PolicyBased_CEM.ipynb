{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCLrRFHSKl_5"
   },
   "source": [
    "# Lunar Lander with Cross-Entropy Method\n",
    "\n",
    "In this notebook we look at the lunar lander environment and solve it with the cross-entropy method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96dExX1TKm2m",
    "outputId": "59a0cc23-613d-4378-8de6-2b4d280e9fa9"
   },
   "outputs": [],
   "source": [
    "#!pip3 install 'gymnasium[box2d]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZXskDwXKl_-"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import deque\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhZ0fzBkKmAA"
   },
   "source": [
    "# Neural Network\n",
    "\n",
    "We define a simple neural network that generates the action scores based on a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vWQr7TZgKmAB"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(obs_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, n_actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zFMlVViKmAE"
   },
   "source": [
    "# Generate Episodes\n",
    "\n",
    "We generate a batch of episodes and remember the traversed states, actions and rewards. To select the next action we use the output of the network. For this we first pass the scores through a softmax to get probabilites. In the second step we sampel from this distribution to get the next action to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIiayltZKmAF"
   },
   "outputs": [],
   "source": [
    "def generate_batch(env, batch_size, t_max=5000):\n",
    "    \n",
    "    activation = nn.Softmax(dim=1)\n",
    "    batch_actions,batch_states, batch_rewards = [],[],[]\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        states, actions = [], []\n",
    "        total_reward = 0\n",
    "        s, _ = env.reset(seed=0)\n",
    "        for t in range(t_max):\n",
    "            \n",
    "            s_v = torch.FloatTensor([s])\n",
    "            act_probs_v = activation(net(s_v))\n",
    "            act_probs = act_probs_v.data.numpy()[0]\n",
    "            a = np.random.choice(len(act_probs), p=act_probs)\n",
    "\n",
    "            new_s, r, done, _, _ = env.step(a)\n",
    "\n",
    "            # record sessions like you did before\n",
    "            states.append(s)\n",
    "            actions.append(a)\n",
    "            total_reward += r\n",
    "\n",
    "            s = new_s\n",
    "            if done:\n",
    "                batch_actions.append(actions)\n",
    "                batch_states.append(states)\n",
    "                batch_rewards.append(total_reward)\n",
    "                break\n",
    "                \n",
    "    return batch_states, batch_actions, batch_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvq2ZIvlKmAJ"
   },
   "source": [
    "# Training\n",
    "\n",
    "In the training step, we first use the neural network to generate a batch of episodes and then use the state-action pairs to improve the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFUzEnaDKmAJ",
    "outputId": "a5344f76-e542-4566-808e-8864fcdd4f09"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "session_size = 100\n",
    "hidden_size = 200\n",
    "completion_score = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "n_states = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "net = Net(n_states, hidden_size, n_actions)\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(session_size):\n",
    "    \n",
    "    # generate new episodes\n",
    "    states, actions, rewards = generate_batch(env, batch_size, t_max=500)\n",
    "    \n",
    "    \n",
    "    # train on the states using actions as targets\n",
    "    for s_i in range(len(states)):\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        tensor_states = torch.FloatTensor(states[s_i])\n",
    "        tensor_actions = torch.LongTensor(actions[s_i])\n",
    "        action_scores_v = net(tensor_states)\n",
    "        loss_v = objective(action_scores_v, tensor_actions)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #show results\n",
    "    mean_reward = np.mean(rewards)\n",
    "    print(\"%d: loss=%.3f, reward_mean=%.1f, threshold=%.1f\" % (\n",
    "            i, loss_v.item(), mean_reward, threshold))\n",
    "    \n",
    "    #check if \n",
    "    if np.mean(rewards)> completion_score:\n",
    "        print(\"Environment has been successfullly completed!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "6_LunarLander_PolicyBased.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
